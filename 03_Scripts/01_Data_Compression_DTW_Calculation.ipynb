{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd # use pandas for more functionality\n",
    "from dtaidistance import dtw\n",
    "\n",
    "# # if dtaidistance does not work with C, use dask for parallelization\n",
    "# from dask import delayed, compute\n",
    "# from dask.distributed import Client, default_client\n",
    "# # Close existing client if any\n",
    "# try:\n",
    "#     client = default_client()\n",
    "#     client.close()\n",
    "# except ValueError:\n",
    "#     pass\n",
    "# client = Client() # Start a new Dask client before importing modin pandas\n",
    "# import modin.pandas as pd # use modin to speed things up (dont use modin wiht Dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory as paerent directory of current directory\n",
    "cwd = os.getcwd()\n",
    "pwd = os.path.dirname(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_stream(row):\n",
    "    # Unpack indices and stream length from the row\n",
    "    indices, stream_length = row['event_timestamps'], row['event_length']\n",
    "\n",
    "    # Initialize a NumPy array of zeros\n",
    "    binary_stream = np.zeros(int(stream_length), dtype=int)\n",
    "\n",
    "    if len(indices) != 0:\n",
    "\n",
    "        # Ensure indices are integers\n",
    "        indices = [int(i) for i in indices if isinstance(i, (int, float)) and not np.isnan(i)]\n",
    "\n",
    "        # Convert indices to a NumPy array and filter out-of-bound indices\n",
    "        indices = np.array(indices)\n",
    "        valid_indices = indices[(0 <= indices) & (indices < int(stream_length))]\n",
    "\n",
    "        # Set the specified indices to 1\n",
    "        binary_stream[valid_indices] = 1\n",
    "\n",
    "    return binary_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_zeros(binary_vector, scaling_factor=10):\n",
    "    if scaling_factor <= 0:\n",
    "        raise ValueError(\"Scaling factor must be greater than 0\")\n",
    "\n",
    "    scaled_vector = []\n",
    "    zero_count = 0\n",
    "\n",
    "    for bit in binary_vector:\n",
    "        if bit == 1:\n",
    "            if zero_count > 0:\n",
    "                # Scale the number of zeros and add them to the new vector\n",
    "                scaled_count = max(1, int(math.ceil(zero_count / scaling_factor)))\n",
    "                scaled_vector.extend([0] * scaled_count)\n",
    "                zero_count = 0\n",
    "            scaled_vector.append(1)\n",
    "        else:\n",
    "            zero_count += 1\n",
    "\n",
    "    # Handle trailing zeros\n",
    "    if zero_count > 0:\n",
    "        scaled_count = max(1, int(math.ceil(zero_count / scaling_factor)))\n",
    "        scaled_vector.extend([0] * scaled_count)\n",
    "\n",
    "    # Convert the list to a NumPy array with a double type\n",
    "    return np.array(scaled_vector, dtype=np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data_df = pd.read_csv(pwd + \"/02_Clean_data/01_recording_event_times_labels_binary.csv\")\n",
    "\n",
    "# Convert string representations of lists to actual lists\n",
    "data_df['event_timestamps'] = data_df['event_timestamps'].apply(ast.literal_eval)\n",
    "# get the binary stream for each row\n",
    "data_df['binary_stream'] = data_df.apply(create_binary_stream, axis=1)\n",
    "\n",
    "# create compressed binary representation\n",
    "# Scale factor\n",
    "# smaller = more compressed\n",
    "scale_factor = 100\n",
    "# Apply the function to each element of the column\n",
    "data_df['scaled_arrays'] = data_df['binary_stream'].apply(lambda x: scale_zeros(x, scale_factor))\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance/Similarity Measurement of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a small subset to calcuylate the distance matrix from\n",
    "scaled_timeseries_lst = data_df['scaled_arrays'].tolist()\n",
    "\n",
    "# calculate the distance matrix\n",
    "# function docs: https://dtaidistance.readthedocs.io/en/latest/modules/dtw.html?highlight=parallel#dtaidistance.dtw.distance_matrix_fast\n",
    "dtw_distance_matrix = dtw.distance_matrix_fast(scaled_timeseries_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save distance matrix for further clustering analysis\n",
    "# Save to .npy file\n",
    "np.save(pwd + \"/02_Clean_data/02_dtw_distance_matrix.npy\", dtw_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if dtaidistance does not work with C\n",
    "\n",
    "# @delayed\n",
    "# def calculate_dtw(i, j):\n",
    "#     distance = dtw.distance(data_df_subset['scaled_arrays'].iloc[i], data_df_subset['scaled_arrays'].iloc[j])\n",
    "#     return i, j, distance\n",
    "\n",
    "# pairs = [(i, j) for i in range(len(data_df_subset)) for j in range(i + 1, len(data_df_subset))]\n",
    "\n",
    "# delayed_results = [calculate_dtw(i, j) for i, j in pairs]\n",
    "\n",
    "# results = compute(*delayed_results)\n",
    "\n",
    "# dtw_matrix = np.full((len(data_df_subset), len(data_df_subset)), None, dtype=float)\n",
    "\n",
    "# for i, j, distance in results:\n",
    "#     dtw_matrix[i][j] = distance\n",
    "#     dtw_matrix[j][i] = distance\n",
    "\n",
    "# np.fill_diagonal(dtw_matrix, 0)\n",
    "\n",
    "# # Remember to close the client when done\n",
    "# client.close()\n",
    "\n",
    "# # dtw_matrix now contains all the pairwise DTW distances\n",
    "# pd.DataFrame(dtw_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "play",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
