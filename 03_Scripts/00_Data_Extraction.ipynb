{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction Notebook\n",
    "Christopher Marais\n",
    "gmarais@ufl.edu\n",
    "2023/12/14\n",
    "\n",
    "This notebook aims to extract the raw data inot a CSV format. THe raw data is in a python class format that has been saved as a binary object using pickle. \n",
    "The python class is described with detail in the multirecording_spikeanalysis.py python script. \n",
    "\n",
    "\n",
    "`/01_Raw_data/phase2_collection.pkl` → `</03_Scripts/00_Data_Extraction.ipynb>` → `/02_Clean_data/00_recording_event_times_labels.csv`\n",
    "\n",
    "This notebook should take approximately 5-10 minutes to run. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import multirecording_spikeanalysis as spike\n",
    "import numpy as np\n",
    "# import pandas as pd # use pandas for more functionality\n",
    "import modin.pandas as pd # use modin to speed things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define working directory relative to repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory as paerent directory of current directory\n",
    "cwd = os.getcwd()\n",
    "pwd = os.path.dirname(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle files given by lab\n",
    "with open(pwd + '/01_Raw_data/phase2_collection.pkl', 'rb') as f:\n",
    "    phase2 = pickle.load(f)\n",
    "\n",
    "# Not using phase 3 data\n",
    "# with open(pwd + '/01_Raw_data/phase3_collection.pkl', 'rb') as f:\n",
    "#     phase3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rework Data from .pkl files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavioral labels and event ranges dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Dask execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    from distributed import Client\n",
      "\n",
      "    client = Client()\n",
      "\n",
      "UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 59396 instead\n",
      "UserWarning: Creating scratch directories is taking a surprisingly long time. (1.74s) This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "# create extracted labels dataframe\n",
    "extracted_labels_df = pd.DataFrame() # create empty dataframe\n",
    "temp_df_lst = [] # create empty list to store dataframes\n",
    "for i, j in phase2.collection.items(): # loop through each recording\n",
    "    temp_df = pd.DataFrame() # create empty dataframe\n",
    "    start_time_lst = [] # create empty list to store start times\n",
    "    end_time_lst = [] # create empty list to store end times\n",
    "    behavior_lab_lst = [] # create empty list to store behavior labels\n",
    "    for k, v in j.event_dict.items(): # loop through each behavior\n",
    "        start_time_lst += list(v[:,0]) # add start times to list\n",
    "        end_time_lst += list(v[:,1]) # add end times to list\n",
    "        behavior_lab_lst += list([k] * len(v)) # add behavior labels to list\n",
    "    temp_df['behavior_label'] = behavior_lab_lst # add behavior labels to dataframe\n",
    "    temp_df['start_time'] = start_time_lst # add start times to dataframe\n",
    "    temp_df['end_time'] = end_time_lst # add end times to dataframe\n",
    "    temp_df['collection_key'] = i # add recording name to dataframe\n",
    "    temp_df['subject'] = j.subject # add subject to dataframe\n",
    "    temp_df_lst.append(temp_df) # add dataframe to list\n",
    "extracted_labels_df = pd.concat(temp_df_lst) # concatenate all dataframes in list to one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: merge is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "# split the order labels from the behaviour labels to a new column\n",
    "# Get a dataframe that only includes the behaviour labels\n",
    "order_df = extracted_labels_df[extracted_labels_df['behavior_label'].isin([\n",
    "    'exposure 1',\n",
    "    'exposure 2', \n",
    "    'exposure 3'])].reset_index(drop=True)\n",
    "order_df = order_df.rename(columns={'behavior_label': 'order'}) # change order label column name\n",
    "\n",
    "# merge dataframes on all columns except the order and behaviour columns\n",
    "merged_order_df = pd.merge(\n",
    "    order_df, \n",
    "    extracted_labels_df, \n",
    "    on=[\n",
    "        'start_time',\n",
    "        'end_time',\n",
    "        'collection_key',\n",
    "        'subject'],\n",
    "    how='right')\n",
    "\n",
    "extracted_labels_df = merged_order_df # rename dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Units dataframe & unit timestamps list\n",
    "Save a dataframe of the units used for each subject at each recording session.\n",
    "\n",
    "Extract the timestamps for each event for each unit from the data.\n",
    "\n",
    "Merge labels dataframes into a single long dataframe. So that data can be easily related to each recording session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "# create metadata dataframe\n",
    "data_df = pd.DataFrame()\n",
    "temp_df_lst = []\n",
    "for i, j in phase2.collection.items():\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['units'] = j.unit_timestamps.keys() # add neurons/units to dataframe\n",
    "    temp_df['timestamps'] = j.unit_timestamps.values() # add neurons/units to dataframe\n",
    "    temp_df['collection_key'] = i # add recording name to dataframe\n",
    "    temp_df['subject'] = j.subject # add subject to dataframe\n",
    "    temp_df_lst.append(temp_df) # add dataframe to list\n",
    "data_df = pd.concat(temp_df_lst) # concatenate all dataframes in list to one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "merged_data_df = pd.merge(extracted_labels_df, data_df, on=['collection_key', 'subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control home much before and after event to include with event.\n",
    "BEFORE_EVENT_BUFFER = 1\n",
    "AFTER_EVENT_BUFFER = 0\n",
    "BEFORE_EVENT_BUFFER = BEFORE_EVENT_BUFFER*20000\n",
    "AFTER_EVENT_BUFFER = AFTER_EVENT_BUFFER*20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: <function Series.tolist> is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "# get list of timestamps for each unit\n",
    "timestamps_lst = merged_data_df['timestamps'].tolist()\n",
    "# Find the length of the longest array\n",
    "max_length = max(arr.size for arr in timestamps_lst)\n",
    "# make a nan array with the same max shape as the array of timestamps\n",
    "timestamps_array = np.full((40866, max_length), np.nan)\n",
    "# Fill in the nan_filled_array with values from timestamps\n",
    "for i, arr in enumerate(timestamps_lst):\n",
    "    timestamps_array[i, :arr.size] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the start and end times for each behavior into arrays\n",
    "min_thresholds = np.array(merged_data_df['start_time']) - BEFORE_EVENT_BUFFER # subtract 20 000 for one extra second before event\n",
    "max_thresholds = np.array(merged_data_df['end_time']) + AFTER_EVENT_BUFFER\n",
    "# Reshape the threshold arrays to column vectors for broadcasting\n",
    "min_thresholds = min_thresholds[:, np.newaxis]\n",
    "max_thresholds = max_thresholds[:, np.newaxis]\n",
    "# Apply thresholds using broadcasting\n",
    "lower_mask = timestamps_array < min_thresholds\n",
    "upper_mask = timestamps_array > max_thresholds\n",
    "# Replace values that are either too low or too high with NaN\n",
    "timestamps_array[lower_mask | upper_mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd # use pandas if modin doesn't work (should be done automatically)\n",
    "# remove nan values from arrays in list\n",
    "event_ts_lst = list(timestamps_array) # convert array to list\n",
    "event_ts_lst = [arr[~np.isnan(arr)] for arr in event_ts_lst] # remove nan values from arrays in list\n",
    "merged_data_df['event_timestamps'] = event_ts_lst # add event timestamps to dataframe\n",
    "# remove all duplicate rows\n",
    "merged_data_df = merged_data_df.drop_duplicates().reset_index(drop=True)\n",
    "# drop all rwos that have exposure 1, 2, or 3 as the behaviour label\n",
    "merged_data_df = merged_data_df[~merged_data_df['behavior_label'].isin([\n",
    "    'exposure 1',\n",
    "    'exposure 2',\n",
    "    'exposure 3'])].reset_index(drop=True)\n",
    "# Convert each float in the lists to an integer\n",
    "merged_data_df['event_timestamps'] = merged_data_df['event_timestamps'].apply(lambda lst: [int(x) for x in lst])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `to_csv` is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: <function Series.tolist> is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: <function Series.tolist> is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "# save dataframe as csv file\n",
    "merged_data_df[['order','start_time','end_time','collection_key','subject','behavior_label','units']].to_csv(pwd + \"/02_Clean_data/00_recording_event_times_labels.csv\", index=False)\n",
    "\n",
    "# save list of arrays to pkl files\n",
    "with open(pwd + \"/02_Clean_data/00_timestamps_arrays_list.pkl\", 'wb') as file:\n",
    "    pickle.dump(merged_data_df['timestamps'].tolist(), file)\n",
    "with open(pwd + \"/02_Clean_data/00_event_timestamps_arrays_list.pkl\", 'wb') as file:\n",
    "    pickle.dump(merged_data_df['event_timestamps'].tolist(), file)\n",
    "# np.save(pwd + \"/02_Clean_data/00_event_timestamps.pkl\", dtw_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>collection_key</th>\n",
       "      <th>subject</th>\n",
       "      <th>behavior_label</th>\n",
       "      <th>units</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>event_timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>24733.0</td>\n",
       "      <td>20230803_101331_1_merged.rec</td>\n",
       "      <td>1.1</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>2</td>\n",
       "      <td>[133, 359, 761, 841, 1042, 1142, 1310, 1398, 1...</td>\n",
       "      <td>[133, 359, 761, 841, 1042, 1142, 1310, 1398, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>24733.0</td>\n",
       "      <td>20230803_101331_1_merged.rec</td>\n",
       "      <td>1.1</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>26</td>\n",
       "      <td>[149, 2407, 2955, 6394, 6924, 11713, 12780, 13...</td>\n",
       "      <td>[149, 2407, 2955, 6394, 6924, 11713, 12780, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>24733.0</td>\n",
       "      <td>20230803_101331_1_merged.rec</td>\n",
       "      <td>1.1</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>196</td>\n",
       "      <td>[394, 1740, 2021, 2752, 3636, 5356, 5854, 6371...</td>\n",
       "      <td>[394, 1740, 2021, 2752, 3636, 5356, 5854, 6371...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>24733.0</td>\n",
       "      <td>20230803_101331_1_merged.rec</td>\n",
       "      <td>1.1</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>113</td>\n",
       "      <td>[436, 7630, 9762, 11461, 13316, 14145, 21222, ...</td>\n",
       "      <td>[436, 7630, 9762, 11461, 13316, 14145, 21222, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>24733.0</td>\n",
       "      <td>20230803_101331_1_merged.rec</td>\n",
       "      <td>1.1</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>91</td>\n",
       "      <td>[449, 4067, 11824, 22087, 32790, 53466, 55978,...</td>\n",
       "      <td>[449, 4067, 11824, 22087]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25593</th>\n",
       "      <td>exposure 3</td>\n",
       "      <td>1985700.0</td>\n",
       "      <td>1986200.0</td>\n",
       "      <td>20230818_133620_1_merged.rec</td>\n",
       "      <td>1.4</td>\n",
       "      <td>novel</td>\n",
       "      <td>73</td>\n",
       "      <td>[352534, 1489090, 3711465, 3936724, 4482099, 6...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25594</th>\n",
       "      <td>exposure 3</td>\n",
       "      <td>1985700.0</td>\n",
       "      <td>1986200.0</td>\n",
       "      <td>20230818_133620_1_merged.rec</td>\n",
       "      <td>1.4</td>\n",
       "      <td>novel</td>\n",
       "      <td>141</td>\n",
       "      <td>[413994, 636033, 764028, 1171529, 1250682, 149...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25595</th>\n",
       "      <td>exposure 3</td>\n",
       "      <td>1985700.0</td>\n",
       "      <td>1986200.0</td>\n",
       "      <td>20230818_133620_1_merged.rec</td>\n",
       "      <td>1.4</td>\n",
       "      <td>novel</td>\n",
       "      <td>36</td>\n",
       "      <td>[449953, 451680, 455769, 458347, 462015, 48572...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25596</th>\n",
       "      <td>exposure 3</td>\n",
       "      <td>1985700.0</td>\n",
       "      <td>1986200.0</td>\n",
       "      <td>20230818_133620_1_merged.rec</td>\n",
       "      <td>1.4</td>\n",
       "      <td>novel</td>\n",
       "      <td>95</td>\n",
       "      <td>[472131, 492784, 527617, 761281, 788850, 93311...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25597</th>\n",
       "      <td>exposure 3</td>\n",
       "      <td>1985700.0</td>\n",
       "      <td>1986200.0</td>\n",
       "      <td>20230818_133620_1_merged.rec</td>\n",
       "      <td>1.4</td>\n",
       "      <td>novel</td>\n",
       "      <td>120</td>\n",
       "      <td>[1431338, 1808996, 2413020, 2448649, 2496858, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25598 rows x 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            order  start_time   end_time                collection_key  \\\n",
       "0             NaN     15167.0    24733.0  20230803_101331_1_merged.rec   \n",
       "1             NaN     15167.0    24733.0  20230803_101331_1_merged.rec   \n",
       "2             NaN     15167.0    24733.0  20230803_101331_1_merged.rec   \n",
       "3             NaN     15167.0    24733.0  20230803_101331_1_merged.rec   \n",
       "4             NaN     15167.0    24733.0  20230803_101331_1_merged.rec   \n",
       "...           ...         ...        ...                           ...   \n",
       "25593  exposure 3   1985700.0  1986200.0  20230818_133620_1_merged.rec   \n",
       "25594  exposure 3   1985700.0  1986200.0  20230818_133620_1_merged.rec   \n",
       "25595  exposure 3   1985700.0  1986200.0  20230818_133620_1_merged.rec   \n",
       "25596  exposure 3   1985700.0  1986200.0  20230818_133620_1_merged.rec   \n",
       "25597  exposure 3   1985700.0  1986200.0  20230818_133620_1_merged.rec   \n",
       "\n",
       "      subject behavior_label  units  \\\n",
       "0         1.1    acquisition      2   \n",
       "1         1.1    acquisition     26   \n",
       "2         1.1    acquisition    196   \n",
       "3         1.1    acquisition    113   \n",
       "4         1.1    acquisition     91   \n",
       "...       ...            ...    ...   \n",
       "25593     1.4          novel     73   \n",
       "25594     1.4          novel    141   \n",
       "25595     1.4          novel     36   \n",
       "25596     1.4          novel     95   \n",
       "25597     1.4          novel    120   \n",
       "\n",
       "                                              timestamps  \\\n",
       "0      [133, 359, 761, 841, 1042, 1142, 1310, 1398, 1...   \n",
       "1      [149, 2407, 2955, 6394, 6924, 11713, 12780, 13...   \n",
       "2      [394, 1740, 2021, 2752, 3636, 5356, 5854, 6371...   \n",
       "3      [436, 7630, 9762, 11461, 13316, 14145, 21222, ...   \n",
       "4      [449, 4067, 11824, 22087, 32790, 53466, 55978,...   \n",
       "...                                                  ...   \n",
       "25593  [352534, 1489090, 3711465, 3936724, 4482099, 6...   \n",
       "25594  [413994, 636033, 764028, 1171529, 1250682, 149...   \n",
       "25595  [449953, 451680, 455769, 458347, 462015, 48572...   \n",
       "25596  [472131, 492784, 527617, 761281, 788850, 93311...   \n",
       "25597  [1431338, 1808996, 2413020, 2448649, 2496858, ...   \n",
       "\n",
       "                                        event_timestamps  \n",
       "0      [133, 359, 761, 841, 1042, 1142, 1310, 1398, 1...  \n",
       "1      [149, 2407, 2955, 6394, 6924, 11713, 12780, 13...  \n",
       "2      [394, 1740, 2021, 2752, 3636, 5356, 5854, 6371...  \n",
       "3      [436, 7630, 9762, 11461, 13316, 14145, 21222, ...  \n",
       "4                              [449, 4067, 11824, 22087]  \n",
       "...                                                  ...  \n",
       "25593                                                 []  \n",
       "25594                                                 []  \n",
       "25595                                                 []  \n",
       "25596                                                 []  \n",
       "25597                                                 []  \n",
       "\n",
       "[25598 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "play",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
