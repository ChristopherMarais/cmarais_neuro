{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import multirecording_spikeanalysis as spike\n",
    "import numpy as np\n",
    "# import pandas as pd # use pandas for more functionality\n",
    "import modin.pandas as pd # use modin to speed things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define working directory relative to repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory as paerent directory of current directory\n",
    "cwd = os.getcwd()\n",
    "pwd = os.path.dirname(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle files given by lab\n",
    "with open(pwd + '/01_Raw_data/phase2_collection.pkl', 'rb') as f:\n",
    "    phase2 = pickle.load(f)\n",
    "\n",
    "# Not usoing phase 3 data\n",
    "# with open(pwd + '/01_Raw_data/phase3_collection.pkl', 'rb') as f:\n",
    "#     phase3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and reminders about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the subject to which each recording belongs to\n",
    "# .subject\n",
    "\n",
    "# shows the type of unit/neuron (we only use good units in unit_timestamps)\n",
    "# .labels_dict\n",
    "\n",
    "# all the timestamps for all units\n",
    "# .timestamps_var\n",
    "\n",
    "# all the timestamps for each unit\n",
    "# .unit_timestamps \n",
    "\n",
    "# the behaviour labels for each timestamp with a starting and ending time\n",
    "# .event_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rework Data from .pkl files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral labels and event ranges dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Dask execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    from distributed import Client\n",
      "\n",
      "    client = Client()\n",
      "\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "# create metadata dataframe\n",
    "metadata_df = pd.DataFrame() # create empty dataframe\n",
    "temp_df_lst = [] # create empty list to store dataframes\n",
    "for i, j in phase2.collection.items(): # loop through each recording\n",
    "    temp_df = pd.DataFrame() # create empty dataframe\n",
    "    start_time_lst = [] # create empty list to store start times\n",
    "    end_time_lst = [] # create empty list to store end times\n",
    "    behavior_lab_lst = [] # create empty list to store behavior labels\n",
    "    for k, v in j.event_dict.items(): # loop through each behavior\n",
    "        start_time_lst += list(v[:,0]) # add start times to list\n",
    "        end_time_lst += list(v[:,1]) # add end times to list\n",
    "        behavior_lab_lst += list([k] * len(v)) # add behavior labels to list\n",
    "    temp_df['behavior_label'] = behavior_lab_lst # add behavior labels to dataframe\n",
    "    temp_df['start_time'] = start_time_lst # add start times to dataframe\n",
    "    temp_df['end_time'] = end_time_lst # add end times to dataframe\n",
    "    temp_df['collection_key'] = i # add recording name to dataframe\n",
    "    temp_df['subject'] = j.subject # add subject to dataframe\n",
    "    temp_df_lst.append(temp_df) # add dataframe to list\n",
    "metadata_df = pd.concat(temp_df_lst) # concatenate all dataframes in list to one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Units dataframe & unit timestamps list\n",
    "Save a dataframe of the units used for each subject at each recording session.\n",
    "Extract the timestamps for each event for each unit from the data.\n",
    "Merge metadata dataframes into a single long dataframe. So that metadata can be easily related to each recording session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "# create metadata dataframe\n",
    "data_df = pd.DataFrame()\n",
    "temp_df_lst = []\n",
    "for i, j in phase2.collection.items():\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['units'] = j.unit_timestamps.keys() # add neurons/units to dataframe\n",
    "    temp_df['timestamps'] = j.unit_timestamps.values() # add neurons/units to dataframe\n",
    "    temp_df['collection_key'] = i # add recording name to dataframe\n",
    "    temp_df['subject'] = j.subject # add subject to dataframe\n",
    "    temp_df_lst.append(temp_df) # add dataframe to list\n",
    "data_df = pd.concat(temp_df_lst) # concatenate all dataframes in list to one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "merged_data_df = pd.merge(metadata_df, data_df, on=['collection_key', 'subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: <function Series.tolist> is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "# get list of timestamps for each unit\n",
    "timestamps_lst = merged_data_df['timestamps'].tolist()\n",
    "\n",
    "# Find the length of the longest array\n",
    "max_length = max(arr.size for arr in timestamps_lst)\n",
    "\n",
    "# make a nan array with the same max shape as the array of timestamps\n",
    "timestamps_array = np.full((40866, max_length), np.nan)\n",
    "\n",
    "# Fill in the nan_filled_array with values from timestamps\n",
    "for i, arr in enumerate(timestamps_lst):\n",
    "    timestamps_array[i, :arr.size] = arr\n",
    "\n",
    "\n",
    "# get the start and end times for each behavior into arrays\n",
    "min_thresholds = np.array(merged_data_df['start_time']) # subtract 20 000 for one extra second before event\n",
    "max_thresholds = np.array(merged_data_df['end_time'])\n",
    "\n",
    "# Reshape the threshold arrays to column vectors for broadcasting\n",
    "min_thresholds = min_thresholds[:, np.newaxis]\n",
    "max_thresholds = max_thresholds[:, np.newaxis]\n",
    "\n",
    "# Apply thresholds using broadcasting\n",
    "lower_mask = timestamps_array < min_thresholds\n",
    "upper_mask = timestamps_array > max_thresholds\n",
    "\n",
    "# Replace values that are either too low or too high with NaN\n",
    "timestamps_array[lower_mask | upper_mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce timestamps to only include timestamps within the event ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THIS PROCESS WORKS CORRECTLY\n",
    "# Limit timestamps data only to event time range\n",
    "# We reduce the start time by 20000 to add another second of data before the event\n",
    "# recordings were done at 20Hz so 20 000 is 1 second\n",
    "# merged_data_df['event_timestamps'] = merged_data_df.apply(lambda row: limit_values(row['timestamps'], row['start_time'] - 20000, row['end_time']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data_df['event_timestamps'] = list(timestamps_array)\n",
    "# merged_data_df.to_csv(pwd + \"/02_Clean_data/recording_data_event_times_nan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `to_csv` is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "timestamps_lst = list(timestamps_array)\n",
    "timestamps_lst = [arr[~np.isnan(arr)] for arr in timestamps_lst]\n",
    "merged_data_df['event_timestamps'] = timestamps_lst\n",
    "merged_data_df.to_csv(pwd + \"/02_Clean_data/recording_data_event_times.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "play",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
